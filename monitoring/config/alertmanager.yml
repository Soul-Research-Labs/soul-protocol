# PIL Monitoring Infrastructure

## Alert Rules Configuration

global:
  resolve_timeout: 5m
  smtp_smarthost: 'smtp.example.com:587'
  smtp_from: 'pil-alerts@example.com'

route:
  receiver: 'default-receiver'
  group_wait: 30s
  group_interval: 5m
  repeat_interval: 4h
  routes:
    - match:
        severity: critical
      receiver: 'critical-receiver'
      continue: true
    - match:
        severity: warning
      receiver: 'warning-receiver'
    - match:
        alertname: ChainDown
      receiver: 'oncall-receiver'
      
receivers:
  - name: 'default-receiver'
    slack_configs:
      - api_url: '${SLACK_WEBHOOK_URL}'
        channel: '#pil-alerts'
        title: '{{ .GroupLabels.alertname }}'
        text: '{{ range .Alerts }}{{ .Annotations.summary }}\n{{ end }}'
        
  - name: 'critical-receiver'
    slack_configs:
      - api_url: '${SLACK_WEBHOOK_URL}'
        channel: '#pil-critical'
        title: 'ðŸš¨ CRITICAL: {{ .GroupLabels.alertname }}'
        text: '{{ range .Alerts }}{{ .Annotations.summary }}\n{{ .Annotations.description }}\n{{ end }}'
    pagerduty_configs:
      - service_key: '${PAGERDUTY_SERVICE_KEY}'
        severity: 'critical'
        
  - name: 'warning-receiver'
    slack_configs:
      - api_url: '${SLACK_WEBHOOK_URL}'
        channel: '#pil-alerts'
        title: 'âš ï¸ WARNING: {{ .GroupLabels.alertname }}'
        text: '{{ range .Alerts }}{{ .Annotations.summary }}\n{{ end }}'
        
  - name: 'oncall-receiver'
    pagerduty_configs:
      - service_key: '${PAGERDUTY_SERVICE_KEY}'
        severity: 'critical'
    slack_configs:
      - api_url: '${SLACK_WEBHOOK_URL}'
        channel: '#pil-oncall'

---
# Prometheus Alert Rules

groups:
  - name: pil_chain_alerts
    rules:
      - alert: ChainDown
        expr: pil_chain_status == 0
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "Chain {{ $labels.chain }} is down"
          description: "Chain {{ $labels.chain }} has been unreachable for more than 2 minutes"
          
      - alert: ChainHighLatency
        expr: pil_chain_latency > 5000
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High latency on chain {{ $labels.chain }}"
          description: "Chain {{ $labels.chain }} latency is {{ $value }}ms"
          
      - alert: ChainDegraded
        expr: pil_chain_latency > 2000 and pil_chain_latency <= 5000
        for: 10m
        labels:
          severity: info
        annotations:
          summary: "Chain {{ $labels.chain }} is degraded"
          description: "Chain {{ $labels.chain }} showing elevated latency"

  - name: pil_bridge_alerts
    rules:
      - alert: BridgeLowSuccessRate
        expr: pil_bridge_success_rate < 95
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "Bridge success rate is low"
          description: "Bridge success rate is {{ $value }}%, below 95% threshold"
          
      - alert: HighPendingTransfers
        expr: pil_pending_transfers > 100
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "High number of pending transfers"
          description: "{{ $value }} transfers pending, indicating possible congestion"
          
      - alert: TransferTimeHigh
        expr: pil_avg_transfer_time > 600
        for: 15m
        labels:
          severity: warning
        annotations:
          summary: "Bridge transfer time is high"
          description: "Average transfer time is {{ $value }}s"
          
      - alert: BridgeVolumeAnomaly
        expr: |
          abs(pil_bridge_volume - avg_over_time(pil_bridge_volume[1d])) 
          > 2 * stddev_over_time(pil_bridge_volume[1d])
        for: 30m
        labels:
          severity: info
        annotations:
          summary: "Unusual bridge volume detected"
          description: "Bridge volume deviates significantly from normal"

  - name: pil_proof_alerts
    rules:
      - alert: ProofGenerationSlow
        expr: pil_proof_generation_time > 10000
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Proof generation is slow"
          description: "Proof generation taking {{ $value }}ms, above 10s threshold"
          
      - alert: ProofVerificationFailures
        expr: rate(pil_proof_failures_total[5m]) > 0.1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Elevated proof verification failures"
          description: "{{ $value }} proof failures per second"
          
      - alert: ProofBacklog
        expr: pil_proof_queue_length > 50
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "Proof generation backlog"
          description: "{{ $value }} proofs queued for generation"

  - name: pil_relayer_alerts
    rules:
      - alert: RelayerDown
        expr: pil_relayer_last_active_seconds > 300
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Relayer {{ $labels.relayer }} inactive"
          description: "Relayer has not been active for {{ $value }}s"
          
      - alert: NoActiveRelayers
        expr: pil_active_relayers == 0
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "No active relayers"
          description: "All relayers are offline or inactive"
          
      - alert: RelayerLowReputation
        expr: pil_relayer_reputation < 50
        for: 30m
        labels:
          severity: warning
        annotations:
          summary: "Relayer {{ $labels.relayer }} has low reputation"
          description: "Relayer reputation is {{ $value }}, below 50 threshold"

  - name: pil_gas_alerts
    rules:
      - alert: HighGasPrice
        expr: pil_gas_price_gwei > 100
        for: 5m
        labels:
          severity: info
        annotations:
          summary: "High gas price on {{ $labels.chain }}"
          description: "Gas price is {{ $value }} gwei"
          
      - alert: GasSpikeDetected
        expr: |
          pil_gas_price_gwei > 2 * avg_over_time(pil_gas_price_gwei[1h])
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Gas price spike on {{ $labels.chain }}"
          description: "Gas price significantly higher than recent average"

  - name: pil_tvl_alerts
    rules:
      - alert: TVLDropped
        expr: |
          (pil_tvl - pil_tvl offset 1h) / pil_tvl offset 1h < -0.1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "TVL dropped significantly"
          description: "TVL decreased by more than 10% in the last hour"
          
      - alert: LargeSingleWithdrawal
        expr: pil_withdrawal_amount > 0.05 * pil_tvl
        labels:
          severity: info
        annotations:
          summary: "Large withdrawal detected"
          description: "Single withdrawal of {{ $value }} (>5% of TVL)"

  - name: pil_security_alerts
    rules:
      - alert: UnusualActivityPattern
        expr: |
          rate(pil_transactions_total[5m]) > 5 * avg_over_time(rate(pil_transactions_total[5m])[1d:5m])
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "Unusual transaction activity"
          description: "Transaction rate significantly above normal"
          
      - alert: FailedTransactionsSpike
        expr: rate(pil_failed_transactions_total[5m]) > 0.5
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Spike in failed transactions"
          description: "{{ $value }} failed transactions per second"
          
      - alert: MultipleSameAddressDeposits
        expr: pil_deposits_same_address_5m > 10
        for: 1m
        labels:
          severity: info
        annotations:
          summary: "Multiple deposits from same address"
          description: "{{ $value }} deposits from same address in 5 minutes"
